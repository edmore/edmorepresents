<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">

    <title>Accelerated Neuroevolution on Core Architectures</title>

    <meta name="description" content="Neuroevolution, Multi-core, Many-core, GPU">
    <meta name="author" content="Edmore Moyo">

    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

    <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>

    <link rel="stylesheet" href="../css/reveal.min.css">
    <link rel="stylesheet" href="../css/theme/beige.msc.css">

    <!-- For syntax highlighting -->
    <link rel="stylesheet" href="../lib/css/zenburn.css">

    <!--[if lt IE 9]>
	<script src="lib/js/html5shiv.js"></script>
	<![endif]-->
  </head>
  <body>
    <div class="reveal">
      <div class="slides">
        <section>
          <h1>Accelerated Neuroevolution on Core Architectures</h1>
          <br>
          <h3><span style="color:white; background-color:black">Edmore Moyo</span></h3>
          <h3>Supervisors : Michelle Kuttel / Geoff Nitschke</h2>
<h3>29 May 2013</h2>
</section>
<!-- Evolution / Genetic Algorithms -->
<section>
  <section>
    <h1>
      <span style="color:white; opacity:0.8">Neuro</span>
      <span style="color: #8b743d">evolution</span>
    </h1>
  </section>
  <section>
    <h2>Evolution ...</h2>
    <blockquote>... is the change in the inherited characteristics of biological populations over successive generations.</blockquote>
    <p><small>~ Wikipedia</small></p>
    <img src="images/homer_evolution.png"></img>
  </section>
  <section>
    <h2>Genetic Algorithms</h2>
    <blockquote>In the computer science field of artificial intelligence, a genetic algorithm (GA) is a search heuristic that mimics the process of natural evolution.</blockquote>
    <p><small>~ Wikipedia</small></p>
  </section>

  <section>
    <h2>Genetic Algorithm</h2>
    <img src="images/genetic_algorithm.png">
  </section>
</section>

<!-- Neural Networks  -->
<section>
  <section>
    <h1>
      <span style="color:#8b743d">Neuro</span>
      <span style="color:white; opacity:0.8">evolution</span>
    </h1>
  </section>
  <section>
    <h2>Biological Neural Networks</h2>
    <blockquote>The human brain can be described as a biological neural
      network, as it is an interconnected web of neurons.</blockquote>
    <img src="images/neuron.png"></img>
  </section>
  <section>
    <h2>Artificial Neural Networks</h2>
    <blockquote>Artificial neural networks are based on the parallel architecture of animal brains and are used for modeling complex relationships
      between inputs and outputs or to find patterns in
      data.</blockquote>
  </section>
  <section>
    <h2>Perceptrons</h2>
    <ul>
      <li class="fragment">The simplest neural network possible is a computational model of a single neuron called a perceptron.</li>
      <li class="fragment">A perceptron can only solve linearly seperable problems e.g. cannot solve XOR.</li>
    </ul>
  </section>

  <section>
    <h2>Multi-layered Perceptrons</h2>
    <ul>
      <li class="fragment">A multi-layered perceptron is a network of perceptrons.</li>
<center><img src="images/ann.svg" class="fragment"></img></center>
<li class="fragment">It can learn to solve more complicated problems.</li>
</ul>
</section>

<section>
  <h2>The key element of Neural Networks ?</h2>
  <p class="fragment">They have the ability to learn</p>
</section>

<section>
  <h2>Classes of Learning Systems</h2>
<ul>
  <li class="fragment">Supervised Learning</li>
  <li class="fragment">UnSupervised Learning</li>
  <li class="fragment">Reinforcement Learning</li>
</ul>
</section>
<section>
  <h2>Reinforcement Learning Systems</h2>
  <blockquote>Reinforcement learning is learning what to do--how to map situations to actions--so as to maximize a numerical reward signal.</blockquote>
  <img src="images/mouse_in_maze.jpg"></img>
</section>

<section>
  <h2>Uses of neural networks?</h2>
  <ul>
    <li>Pattern recognition</li>
    <li>Time Series Prediction</li>
    <li>Robotics</li>
    <li>Control</li>
  </ul>
</section>

</section>

<section>
  <section>
    <h1>Neuroevolution</h1>
    <blockquote>Neuroevolution (NE) is a method for modifying neural
      network weights, topologies, or ensembles, with a genetic
      algorithm, in order for the network to learn a specific
      task</blockquote>
    <p><small>~ Risto Miikkulainen</small></p>
  </section>

  <section>
    <h2>NE is a supervised learning method.</h2>
  </section>

  <section>
    <h2>Examples of NE methods</h2>
    <ul >
      <li >Symbiotic Adaptive Neuroevolution (SANE)</span></h3>
      <li >Enforced Sub-populations (ESP)</span></h3>
      <li >Neuroevolution Augmenting Topologies (NEAT)</span></h3>
      <li >Potter and De Jong</li>
      <li >Multi-Component ESP</li>
      <li >... and many more</li>
    </ul>
  </section>

  <section>
    <h2>Examples of population based NE methods</h2>
    <ul>
      <li >Symbiotic Adaptive Neuroevolution (SANE)</li>
      <li >Enforced Sub-populations (ESP)</li>
      <li >Potter and De Jong</li>
      <li >CONE</li>
    </ul>
  </section>

  <section>
    <h2>Enforced Sub-populations (ESP)</h2>
    <img src="images/esp.png"></img>
  </section>

  <section>
    <h2>Cooperative Coevolution</h2>
    <ul>
      <li>The ESP method can be extended to evolving multiple networks simultaneously, and applied to multi-agent problem solving tasks.</li>
      <li >Multi-agent neuroevolution is a promising approach for complex real-world tasks.</li>
    </ul>

  </section>

</section>


<section>

  <section>
    <h1>Core Architectures</h1>
    <ul>
      <li class="fragment"><span>PARALLELISM</span></li>
      <li class="fragment"><span>CONCURRENCY</span></li>
    </ul>
</section>

  <section>
    <h1>Parallelism</h1>
    <ul>
      <li class="fragment"><span>MULTI-CORE</span></li>
      <li class="fragment"><span>MANY-CORE</span></li>
    </ul>
  </section>

<section>
  <h1>Multi-core</h1>
<p> Pretty much mainstream. On most modern devices, from phones, laptops, to workstations. Many applications exist that still do not utilise all cores.</p>
  <ul>
  </ul>
</section>

<section>
  <h1>Many-core</h1>
<p> This includes Graphics Processing Units (GPUs), Coprocessors, like the Xeon Phi Coprocessor, and Coupled CPU/GPU architectures. There is a growing use of this hardware for accelerating applications to achieve massive parallelism. It is still, however, difficult to program for GPUs, even though vendor specific platforms, such as CUDA, are available.</p>
  <ul>
  </ul>
</section>

<section>
  <h1>Concurrency</h1>
  <blockquote>Concurrency is powerful.<br>
    Concurrency is not parallelism.<br>
    Concurrency enables parallelism.</br>
    Concurrency makes parallelism (and scaling and everything else) easy.</br>
    <p><small>~ Rob Pike</small></p>
  </blockquote>
</section>

<section>
  <h1>Go</h1>
  <ul>
    <img src="images/gopher.png"></img>
  </ul>
</section>

<section>
  <h1>What is Go?</h1>
  <ul>
    <li ><span> open source</span></li>
    <li ><span> closely based on C.A.R HOARE'S CSP</span></li>
    <li ><span> built in concurrency - goroutines and channels</span></li>
    <li ><span> garbage collected</span></li>
    <li ><span> easy to program in - C like</span></li>
    <li ><span > statically typed with fast compilation</span></li>
    <li ><span > ... It also has a pretty cool mascot!</span></li>
  </ul>
</section>

</section>

<section>

<section>
  <h1>What do we already know?</h1>
</section>

<section>
<h2>
<blockquote>Is there a future for ANN hardware?</blockquote>
</h2>
    <p><small>~ Cabestany et al. (1996)</small></p>
</section>

<section>
  <h3>There have been attempts to speed up the training of neural networks through parallelisation</h3>
  <ul>
    <li><span >Most published work is on Field Programmable Gate Arrays (FPGAs)</span></li>
    <li><span >It has been stated that FPGA implementations of ANNs, with a large number of neurons is "challenging", because of the multiplication intensive nature of ANNs</span></li>
  </ul>
</section>

<section>
  <h3>Suggestions have been made for more "hardware-friendly" algorithms to be developed</h3>
<ul>
<p>There is published work on the parallelisation of genetic algorithms using MapReduce.</p>
</ul>
<div class="fragment">
<blockquote>MapReduce is a programming model and an associated implementation for processing and generating large data sets.</blockquote>
    <p><small>~ Google</small></p>
<div>
</section>

  <section>
    <h2>To our knowledge, there is no published work on accelerating the NE Method ESP through parallelisation, on multi-core or many-core architectures.</h2>
  </section>

<section>
<h2>But why would we want to accelerate neuroevolution?</h2>
</section>

<section>
<h2>Why?</h2>
  <ul>
    <li ><span> Current implementations are serial and do not utilize all cores effectively </span></li>
    <li ><span> NE is an efficient method for finding an optimal solution to complex problems and can benefit from being faster</span></li>
    <li ><span> NE is general, can be used to train feed-forward as well as recurrent neural networks</span></li>
  </ul>

</section>

<section>
<h2>Why?</h2>
  <ul>
    <li ><span > The disadvantage is that it requires many trials and is therefore compute intensive.</span></li>
    <li ><span > Some real world problems require a solution in a relatively short time</span></li>
    <li ><span > Some applications are large, with a large number of neurons, that require frequent and lengthy retraining</span></li>
  </ul>
</section>


</section>

<section>
  <section>
    <h1>How will this study contribute?</h1>
  </section>

  <section>
    <h2>Aims</h2>
    <ul>
      <p><span >The aim of this study is to accelerate neuroevolution by parallelisation of the ESP method.</span></p>
    </ul>
  </section>

  <section>
    <h2>Research Questions</h2>
<ul>
<li class="fragment">Is it possible to develop an efficient, scalable, parallel implementation of the ESP method?</li>
<li class="fragment">Can the ESP algorithm be expressed and parallelised using the MapReduce Model?</li>
<li class="fragment">Is the implementation portable?</li>
</ul>
  </section>

  <section>
    <h2>Approach</h2>
  <ul>
    <li ><span style=""> A study of the current serial implementations of ESP  </span></li>
    <li ><span style=""> Optimization of the ESP algorithm - an attempt to use the MapReduce model</span></li>
    <li ><span style=""> Implementation of a multi-core version of ESP in Go</span></li>
    <li ><span style=""> Time permitting - an implementation of a many-core version </span></li>
  </ul>

  </section>

  <section>
    <h2>Testing and Evaluation</h2>
<ul>
    <li ><span style="">Pole-balancing / Inverted pendulum task (ESP)</span></li>
    <li ><span style=""> Predator-prey task (Multi-Component ESP)</span></li>
</ul>
  </section>

  <section>
    <h2>Key Milestones</h2>
<ul>
    <li ><span style="">Research Proposal</span></li>
    <li ><span style="">Implementation of parallel, multi-core version of ESP, in Go</span></li>
    <li ><span style="">Testing and Evaluation</span></li>
    <li ><span style="">Submission of journal or conference paper</span></li>
    <li ><span style="">Dissertation Write-up and submission</span></li>
</ul>

  </section>

</section>

<!-- References -->
<section>
  <h2>References</h2>
  <ul style="font-size:0.5em">
    <li>http://www.ironammonite.com/2011/05/top-5-evolution-in-minute-videos-on-tv_19.html</li>
    <li>http://natureofcode.com/book/</li>
    <li>http://www.nextnature.net/2010/01/as-smart-as-mice/</li>
    <li>http://webdocs.cs.ualberta.ca/~sutton/book/ebook/node7.html</li>
    <li>http://en.wikipedia.org/wiki/File:Neural_network_example.svg</li>
    <li>http://www.cs.utexas.edu/users/nn/pages/research/neuroevolution.html</li>
    <li>http://tip.golang.org/doc/gopher/</li>
    <li>http://talks.golang.org/2012/waza.slide#58</li>
    <li>http://golang.org</li>
<li>http://research.google.com/archive/mapreduce.html</li>
<li>J Cabestany, P Ienne, J M Moreno, and J Madrenas. Is there a future for ann hardware? 1996.</li>
<li>Perry Moerland and Emile Fiesler. Neural Network Adaptations to Hardware Implementations. 1997.</li>
<li>Jihan Zhu and Peter Sutton. FPGA Implementa- tions of Neural Networks - a Survey of a Decade of Progress A Taxonomy of FPGA Implementations of ANNs. pages 1–4, 2003.</li>
  </ul>
</section>

<section>
  <h1>The End</h1>
  <p><h3>By</h3></p>
  <p> Edmore Moyo / @etmoyo / www.edmoremoyo.com </p>
  <p><a href="https://github.com/edmore/edmorepresents/tree/master/public/slides/NE">Source code on github</a></p>
</section>
</div>

<!-- Presentation progress bar -->
<div class="progress"><span></span></div>

</div>
</div>
<script src="../lib/js/head.min.js"></script>
<script src="../js/reveal.min.js"></script>

<script>

  // Full list of configuration options available here:
  // https://github.com/hakimel/reveal.js#configuration
  Reveal.initialize({
  controls: true,
  progress: true,
  history: true,
  transition: 'default'
  });

</script>
</body>
</html>

